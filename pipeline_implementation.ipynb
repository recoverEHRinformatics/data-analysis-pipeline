{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook we will combine all the predefined functions from other notebooks to run a compelete data analysis pipeline. \n",
    "\n",
    "NOTE 1: We are limiting the patient cohort for this analysis to all patients in  _**qtwg.\\<SCHEMA\\>_index_all**_ table for each site. These custom tables were generated using SQL query to identify all patients 1) who have been tested for COVID-19 (regardless of result), 2) had a COVID-19 diagnosis of U07.1, or 3) recived Paxlovid per site. To learn more about the SQL query used to generate these custom tables.\n",
    "\n",
    "NOTE 2: We are restricting the data points up to the end of the study period. The study period start and end dates are defined as variables that will be used across this notebook. Please make sure to change these dates if necessary.\n",
    "\n",
    "NOTE 3: We are only querying 5 sites for this walkthrough. The list of sites are stored as a Python list of strings. Please make sure to modify the list if necessary. Please keep in mind some sites may not have _**qtwg.\\<SCHEMA\\>_index_all**_ table yet. If that's the case please contact Sajjad Abedian at saa3011@med.cornell.edu.\n",
    "\n",
    "This notebook will cover walkthrough showing:\n",
    "1. **Raw data extraction**: Querying live raw data from RECOVER adult database\n",
    "2. **Data wrangling**: Using pre-defined functions for data wrangling\n",
    "3. **Analysis**: Calculating the PASC rate for patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any of the modules above are not already installed please use the command below in your notebook to install the module\n",
    "# !pip install NameOfYourModule (e.g. !pip install pandas)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import text as sqlalchemy_text\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of site names used in the analysis\n",
    "# the site names should exactly match the schema names live in the database\n",
    "site_names = ['site1', 'site2', 'site3', 'site4', 'site5']\n",
    "\n",
    "# Study period start and end date (YYYY-MM-DD)\n",
    "study_start_date = '2020-03-01'\n",
    "study_end_date = '2022-07-30'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main folder of the query\n",
    "main_path = \"\"\n",
    "\n",
    "# where the raw data will be saved\n",
    "source_data_path = f\"{main_path}/source data\"\n",
    "# create an empty folder if it does not exist\n",
    "if os.path.exists(source_data_path) != True:\n",
    "    os.makedirs(source_data_path)\n",
    "\n",
    "# where the results will be saved\n",
    "result_path = f\"{main_path}/result\"\n",
    "# create an empty folder if it does not exist\n",
    "if os.path.exists(result_path) != True:\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "# where all external data needed for analysis is already saved (e.g. PASC definition spreadsheet)\n",
    "external_source_path = \"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_data(query: str, site_names: list, source_data_path: str, data_name: str, database_engine: str):\n",
    "    '''extract_raw_data is a function to query the live data for all sites in the analysis, concatenate them together, and save them as parquet files.\n",
    "\n",
    "    Args:\n",
    "        query (str): SQL query to be executed aginst the live data in database.\n",
    "        site_names (list): a list of all site names (schemas as they appear in the database) used in the analysis.\n",
    "        source_data_path (str): the source data folder path where the final data frame will be saved.\n",
    "        data_name (str): name of the table as it appears in the database.\n",
    "        database_engine (str): the database engine address.\n",
    "\n",
    "    Returns:\n",
    "        final_df (DataFrame): a pandas dataframe containing all sites data\n",
    "    '''\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "    counter = 1\n",
    "\n",
    "    for site in site_names:\n",
    "        try:\n",
    "            print(f\"Query {counter}. {site}'s {data_name} started\")\n",
    "\n",
    "            # replace where input query indicates \"<SCHEMA>\" with the site's real schema\n",
    "            modified_query = query.replace(\"<SCHEMA>\", f\"{site}\")\n",
    "\n",
    "            df = pd.read_sql(\n",
    "                modified_query, database_engine\n",
    "            )\n",
    "            # creating an additional column to indicate the site\n",
    "            df['site'] = site\n",
    "            print(f\"{site}'s {data_name} query is finished\")\n",
    "\n",
    "            # optional lines to generate information about each site's data\n",
    "            print(f\"{site} table shape: {df.shape}\")\n",
    "            print(f\"{site} table has: {len(df.syn_pt_id.unique())} unique patients\")\n",
    "\n",
    "            # concatenate individual site data into one data frame (i.e. final_df)\n",
    "            final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "            del df\n",
    "            counter += 1\n",
    "            print(\"*\"*50)\n",
    "\n",
    "        # error-agnostic pass which will leave out the individual site\n",
    "        # make sure to investigate further why the query failed for a specific site\n",
    "        # best way to investigate the issue is to run the SQL query in PgAdmin\n",
    "        # possible issues could be data type mismatch for certain columns\n",
    "        except:\n",
    "            error_msg = f\"# {counter}. {site}'s {data_name} WAS NOT PROCESSED #\"\n",
    "            print(\"#\"*len(error_msg))\n",
    "            print(error_msg)\n",
    "            print(\"#\"*len(error_msg))\n",
    "\n",
    "    # saving the table with all sites data concatenated as parquet format in source data folder\n",
    "    pq.write_table(pa.Table.from_pandas(\n",
    "        final_df), f\"{source_data_path}/{data_name}.parquet\", compression=\"BROTLI\")\n",
    "    print(f\"All sites {data_name} data have been saved as a parquet file in:\")\n",
    "    print(f\"{source_data_path}/{data_name}.parquet\")\n",
    "\n",
    "    # optional lines to generate information about all sites data\n",
    "    print(f\"{site} table shape: {final_df.shape}\")\n",
    "    print(f\"{site} table has: {len(final_df.syn_pt_id.unique())} unique patients\")\n",
    "    print(f\"{site} table has: {len(final_df.site.unique())} unique sites\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the empty strings below with the correct server/database information\n",
    "server = \"\"\n",
    "database = \"\"\n",
    "username = \"\"\n",
    "password = \"\"\n",
    "port = ''\n",
    "\n",
    "database_string = f\"postgres+psycopg2://{username}:{password}@{server}:{port}/{database}\"\n",
    "\n",
    "database_engine = create_engine(database_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_demographic = f\"\"\"\n",
    "SELECT\n",
    "CONCAT({\"'<SCHEMA>'\"}, '_', patid) AS syn_pt_id\n",
    ", t1.patid, t1.birth_date, t1.race, t1.hispanic, t1.sex\n",
    "FROM <SCHEMA>.demographic t1\n",
    "WHERE t1.patid in (\n",
    "    SELECT patid FROM qtwg.<SCHEMA>_index_all \n",
    "    WHERE index_date >= '{study_start_date}' AND index_date <= '{study_end_date}'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "demographic = extract_raw_data(\n",
    "    query=query_demographic, \n",
    "    site_names=site_names, \n",
    "    source_data_path=source_data_path, \n",
    "    data_name='demographic',\n",
    "    database_engine=database_engine)\n",
    "\n",
    "\n",
    "del query_demographic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please note we are limiting the records in this table up to the end of the study period\n",
    "query_diagnosis = f\"\"\"\n",
    "SELECT\n",
    "CONCAT({\"'<SCHEMA>'\"}, '_', patid) AS syn_pt_id\n",
    ", t1.patid, t1.admit_date, t1.dx\n",
    "FROM <SCHEMA>.diagnosis t1\n",
    "WHERE t1.patid in (\n",
    "        SELECT patid FROM qtwg.<SCHEMA>_index_all \n",
    "        WHERE index_date >= '{study_start_date}' AND index_date <= '{study_end_date}'\n",
    "        )\n",
    "    AND t1.admit_date <= '{study_end_date}';\n",
    "\"\"\"\n",
    "\n",
    "diagnosis = extract_raw_data(\n",
    "    query=query_diagnosis, \n",
    "    site_names=site_names, \n",
    "    source_data_path=source_data_path, \n",
    "    data_name='diagnosis',\n",
    "    database_engine=database_engine)\n",
    "\n",
    "\n",
    "del query_diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please note we are limiting the records in this table up to the end of the study period\n",
    "query_index_all = f\"\"\"\n",
    "SELECT\n",
    "CONCAT({\"'<SCHEMA>'\"}, '_', patid) AS syn_pt_id\n",
    ", t1.patid, t1.index_date, t1.index_type, t1.index_result, t1.enc_type\n",
    "FROM qtwg.<SCHEMA>_index_all t1\n",
    "WHERE t1.index_date >= '{study_start_date}' AND t1.index_date <= '{study_end_date}';\n",
    "\"\"\"\n",
    "\n",
    "index_all = extract_raw_data(\n",
    "    query=query_index_all, \n",
    "    site_names=site_names, \n",
    "    source_data_path=source_data_path, \n",
    "    data_name='index_all',\n",
    "    database_engine=database_engine)\n",
    "\n",
    "\n",
    "del query_index_all\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify COVID patients \n",
    "At this stage we will identify patients who meet the definition of COVID-19 patients.\n",
    "\n",
    "COVID-19 patients must meet at least one of the following criteria:\n",
    "1. At least one positive PCR or antigen lab test\n",
    "2. At least one COVID-19 diagnosis (U07.1) in an inpatient setting\n",
    "3. At least two COVID-19 diagnosis (U07.1) in an outpatient setting\n",
    "\n",
    "Please note, for this analysis we do not consider Paxlovid prescription as a COVID-19 indication."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lab_pts(index_all: pd.DataFrame, patid_column='syn_pt_id'):\n",
    "    '''get_lab_pts finds the list of all patients with at least one positive COVID-19 PCR or antigen lab \n",
    "\n",
    "    Args:\n",
    "        index_all (pd.DataFrame): a dataframe contianing all COVID-19 indications.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "\n",
    "    Returns:\n",
    "        list: all patients with at least one COVID-19 PCR or antigen test\n",
    "    '''\n",
    "\n",
    "    # at least 1 positive PCR or antigen test\n",
    "    covid_lab = index_all.query(\n",
    "        \"index_type == 'lab' and index_result == 'positive'\")\n",
    "    covid_lab = list(set(covid_lab[patid_column]))\n",
    "\n",
    "    return covid_lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ip_dx_pts(index_all: pd.DataFrame, patid_column='syn_pt_id'):\n",
    "    '''get_ip_dx_pts finds the list of all patients with at least one COVID-19 dx in an inpatient setting\n",
    "\n",
    "    Args:\n",
    "        index_all (pd.DataFrame): a dataframe contianing all COVID-19 indications.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "\n",
    "    Returns:\n",
    "        list: all patients with at least one dx in an inpatient setting\n",
    "    '''\n",
    "\n",
    "    covid_ip = index_all[(index_all['index_type'] == 'covid_dx') & (\n",
    "        index_all['enc_type'].isin(['IP', 'EI']))]\n",
    "\n",
    "    covid_ip = list(set(covid_ip[patid_column]))\n",
    "\n",
    "    return covid_ip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_av_dx_pts(index_all: pd.DataFrame, patid_column='syn_pt_id'):\n",
    "    '''get_av_dx_pts finds the list of all patients with at least one COVID-19 dx in an outpatient setting\n",
    "\n",
    "    Args:\n",
    "        index_all (pd.DataFrame): a dataframe contianing all COVID-19 indications.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "\n",
    "    Returns:\n",
    "        list: all patients with at least one dx in an outpatient setting\n",
    "    '''\n",
    "\n",
    "    covid_av = index_all[(index_all['index_type'] == 'covid_dx') & (\n",
    "        index_all['enc_type'].isin(['AV', 'ED', 'TH', 'OA']))]\n",
    "\n",
    "    covid_av = list(set(covid_av[patid_column]))\n",
    "\n",
    "    return covid_av\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_two_av_dx_pts(index_all: pd.DataFrame, patid_column='syn_pt_id'):\n",
    "    '''get_two_av_dx_pts finds the list of all patients with at least two COVID-19 dx in an outpatient setting\n",
    "\n",
    "    Args:\n",
    "        index_all (pd.DataFrame): a dataframe contianing all COVID-19 indications.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "\n",
    "    Returns:\n",
    "        list: all patients with at least two dx in an outpatient setting\n",
    "    '''\n",
    "\n",
    "    covid_av_two = index_all[(index_all['index_type'] == 'covid_dx') & (\n",
    "        index_all['enc_type'].isin(['AV', 'ED', 'TH', 'OA']))]\n",
    "\n",
    "    # count the number of outpatient dx per patient\n",
    "    covid_av_two = covid_av_two[[patid_column, 'index_date']].groupby(\n",
    "        patid_column).nunique().reset_index()\n",
    "    # patients with at least 2 outpatient dx\n",
    "    covid_av_two = covid_av_two[covid_av_two['index_date'] >= 2]\n",
    "    covid_av_two = list(set(covid_av_two[patid_column]))\n",
    "\n",
    "    return covid_av_two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paxlovid_pts(index_all:pd.DataFrame, patid_column='syn_pt_id'):\n",
    "    '''get_paxlovid_pts finds the list of all patients with at least one paxlovid prescription\n",
    "\n",
    "    Args:\n",
    "        index_all (pd.DataFrame): a dataframe contianing all COVID-19 indications.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "\n",
    "    Returns:\n",
    "        list: all patients with at one paxlovid prescription\n",
    "    '''\n",
    "\n",
    "    covid_paxlovid = index_all[index_all.index_type=='paxlovid']\n",
    "    covid_paxlovid = list(set(covid_paxlovid[patid_column]))\n",
    "\n",
    "    return covid_paxlovid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_event(df: pd.DataFrame, index_date_column='index_date', patid_column='syn_pt_id', start_date=study_start_date, end_date=study_end_date):\n",
    "    '''get_index_event function finds the first instance of an index event per patient\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): a dataframe with all instances of covid indication for all patients (i.e. positive lab, dx, and etc.)\n",
    "        index_date_column (str, optional): the column in the dataframe indicating the date. Defaults to 'index_date'.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "        start_date (str, optional): start of the study period. Defaults to study_start_date variable.\n",
    "        end_date (str, optional): end of the study period. Defaults to study_end_date variable.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: returns a dataframe with one row per patient inidicating the first instance of the index event\n",
    "    '''\n",
    "\n",
    "    start_date = pd.to_datetime(start_date).date()\n",
    "    end_date = pd.to_datetime(end_date).date()\n",
    "\n",
    "    index = df[(df[index_date_column] >= start_date)\n",
    "               & (df[index_date_column] <= end_date)]\n",
    "\n",
    "    index = index.sort_values(index_date_column).drop_duplicates(patid_column)\n",
    "    index.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude any COVID-19 indication outside of the study period time interval\n",
    "index_all = index_all[\n",
    "    (index_all['index_date'] >= pd.to_datetime(study_start_date).date())\n",
    "    &\n",
    "    (index_all['index_date'] <= pd.to_datetime(study_end_date).date())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find patients with at least two outpatient covid dx\n",
    "covid_av_two = get_two_av_dx_pts(\n",
    "    index_all=index_all,\n",
    "    patid_column='syn_pt_id'\n",
    ")\n",
    "\n",
    "# find patients with at least one inpatient covid dx\n",
    "covid_ip = get_ip_dx_pts(\n",
    "    index_all=index_all,\n",
    "    patid_column='syn_pt_id'\n",
    ")\n",
    "\n",
    "# find patients with at least one covid lab\n",
    "covid_lab = get_lab_pts(\n",
    "    index_all=index_all,\n",
    "    patid_column='syn_pt_id'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataframe to include only diagnoses and positive lab instances\n",
    "temp_index_all = index_all[\n",
    "    # patients who meet any of the COVID-19 definition described above\n",
    "    (index_all.syn_pt_id.isin(covid_av_two + covid_lab + covid_ip))\n",
    "    # excluding index events the COVID-19 indication is paxlovid\n",
    "    & ~(index_all.index_type == 'paxlovid')\n",
    "    # excluding index events where the lab result is negative\n",
    "    & ~((index_all.index_type == 'lab') & (index_all.index_result == 'negative'))\n",
    "]\n",
    "\n",
    "# using get_index_event to find the first instance of COVID-19 indication for each patient\n",
    "index = get_index_event(\n",
    "    df=temp_index_all,\n",
    "    index_date_column='index_date',\n",
    "    patid_column='syn_pt_id',\n",
    "    start_date=study_start_date,\n",
    "    end_date=study_end_date\n",
    ")\n",
    "\n",
    "del temp_index_all\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify PASC patients\n",
    "At this stage we use the PASC definition reference spreadsheet to identify the PASC like symptoms for all patients. Then by comparing the date of the first diagnosis per category to the index date, we find the PASC patients.\n",
    "\n",
    "### Pre-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pasc_category(diagnosis: pd.DataFrame, index: pd.DataFrame, PASC_definition_reference: pd.DataFrame, patid_column='syn_pt_id', category='ccsr_category'):\n",
    "    '''get_pasc_category function finds the date of first instance of all PASC like diagnosis for each patient.\n",
    "    The resulting dataframes from this function will be used to identify date of PASC diagnosis and subphenotypes. \n",
    "\n",
    "    Args:\n",
    "        diagnosis (pd.DataFrame): standard diagnosis table from PCORnet CDM containing all diagnoses for patients.\n",
    "        index (pd.DataFrame): custom index table created using a pre-defined function containing the index dates for each patient.\n",
    "        PASC_definition_reference (pd.DataFrame): a reference spreadsheet containing all ICD-10 codes and diagnosis categories of PASC-like symptoms.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "        category (str, optional): Diagnosis category column in the PASC_definition_reference table. Defaults to 'ccsr_category'.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two pandas dataframe. Both dataframes have one unique row per patient and each diagnosis category as a column. \n",
    "        categorized_diff: the values for each column is the time difference (in days) between the index date and the first instance of the diagnosis\n",
    "        categorized_date: the date of first instance of the diagnosis\n",
    "    '''\n",
    "\n",
    "    # merge with index table to get the first instance of index event\n",
    "    dx = pd.merge(\n",
    "        diagnosis,\n",
    "        index[[patid_column, 'index_date']],\n",
    "        on=patid_column, how='inner'\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    # calculate the difference in days between the diagnosis date and index event date\n",
    "    # date_diff_from_index < 0 means the diagnosis was recorded before the index event date\n",
    "    # date_diff_from_index > 0 means the diagnosis was recorded after the index event date\n",
    "    dx['date_diff_from_index'] = (\n",
    "        dx['admit_date'] - dx['index_date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    # select the columns needed and drop duplicates\n",
    "    dx.drop(columns=['site'], inplace=True)\n",
    "    dx.drop_duplicates(inplace=True)\n",
    "\n",
    "    # join to PASC_defintion to get the dx category if it is a PASC dx\n",
    "    dx = pd.merge(\n",
    "        dx,\n",
    "        PASC_definition_reference[['i10_code', category]],\n",
    "        left_on='dx',\n",
    "        right_on='i10_code',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # throw away any diagnoses in the blackout period and\n",
    "    # balckout period is defined as 7 days before and 30 days after the index date\n",
    "    dx = dx[\n",
    "        ~(dx['date_diff_from_index'].between(-7, 30, inclusive='neither'))\n",
    "    ]\n",
    "\n",
    "    # throw away any diagnoses 180 days after the index date\n",
    "    dx = dx[dx['date_diff_from_index'] <= 180]\n",
    "\n",
    "    # select the necessary columns and drop the duplicates\n",
    "    # by only including the CCSR category column (i.e. ccsr_category) and excluding the ICD-10 code column (i10_code)\n",
    "    # we ensure that if there are several ICD-10 codes with the same category, we count them as the same\n",
    "    dx = dx[[patid_column, 'date_diff_from_index', category, 'admit_date']].copy()\n",
    "    dx.drop_duplicates(inplace=True)\n",
    "    dx.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # create a pivot table with each column representing the smallest value of date_diff_from_index\n",
    "    # negative number means this is not a PASC diagnosis and it was previously present for this patient\n",
    "    # positive number means this is a PASC diagnosis and the patient developed this diagnosis after index event date\n",
    "    # 0 as a value means this diagnosis was developed at the same time as the index event date\n",
    "    # NaN means the patient has never been diagnosed with this particular diagnosis\n",
    "    categorized_diff = dx.pivot_table(\n",
    "        index=[patid_column],\n",
    "        columns=[category],\n",
    "        values='date_diff_from_index',\n",
    "        aggfunc='min')\n",
    "    categorized_diff.drop_duplicates(inplace=True)\n",
    "\n",
    "    # create a pivot table with each column representing the date of the first instance of a diagnosis in that category\n",
    "    # NaN means the patient has never been diagnosed\n",
    "    categorized_date = dx.sort_values(\n",
    "        [patid_column, 'admit_date']).drop_duplicates(patid_column)\n",
    "    categorized_date = categorized_date.pivot(\n",
    "        index=[patid_column], columns=[category], values='admit_date')\n",
    "\n",
    "    categorized_date.reset_index(inplace=True)\n",
    "    categorized_diff.reset_index(level=patid_column, inplace=True)\n",
    "\n",
    "    return categorized_diff, categorized_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pasc_subphenotype(pasc_diff: pd.DataFrame, patid_column='syn_pt_id'):\n",
    "    '''get_pasc_subphenotype function identifies one subphenotype per patient\n",
    "\n",
    "    Args:\n",
    "        pasc_diff (pd.DataFrame): the first returned result (i.e. categorized_diff) from get_pasc_category function\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a dataframe with a unique row per patient indicating one PASC subphenotype\n",
    "    '''\n",
    "\n",
    "    # set patid_column as the index\n",
    "    temp_df = pasc_diff.copy()\n",
    "    temp_df.set_index(patid_column, inplace=True)\n",
    "    # replace negative values with nan to only focus on the real PASC diagnoses\n",
    "    # negative values represent pre-existing diagnosis and are not PASC\n",
    "    temp_df[temp_df < 0] = np.nan\n",
    "\n",
    "    # find the column NAME that has the smallest value (.idxmin(axis=1))\n",
    "    # column NAME will indicate the subphenotype name\n",
    "    pasc_subphenotype = pd.DataFrame(temp_df.idxmin(\n",
    "        axis=1, skipna=True), columns=['subphenotype_name'])\n",
    "\n",
    "    # find the smallest column VALUE (.min(axis=1))\n",
    "    # the smallest value across all columns indicate date difference (in days) between the index date and the first instance of PASC diagnosis\n",
    "    pasc_subphenotype = pasc_subphenotype.merge(\n",
    "        pd.DataFrame(temp_df.min(axis=1, skipna=True),\n",
    "                     columns=['subphenotype_days']),\n",
    "        on=patid_column,\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # resetting the index will make the patid_column to be a regular column rather than the index for this dataframe\n",
    "    pasc_subphenotype.reset_index(inplace=True)\n",
    "\n",
    "    # categorize the interval\n",
    "    pasc_subphenotype['subphenotype_interval'] = np.select(\n",
    "        [\n",
    "            pasc_subphenotype['subphenotype_days'].between(30, 59, inclusive='both'), \n",
    "            pasc_subphenotype['subphenotype_days'].between(60, 89, inclusive='both'), \n",
    "            pasc_subphenotype['subphenotype_days'].between(90, 119, inclusive='both'),\n",
    "            pasc_subphenotype['subphenotype_days'].between(120, 149, inclusive='left'), \n",
    "            pasc_subphenotype['subphenotype_days'] >= 150\n",
    "        ], [\n",
    "            '30-59', \n",
    "            '60-89', \n",
    "            '90-119', \n",
    "            '120-149', \n",
    "            '150+'\n",
    "        ], default=np.NaN\n",
    "    )\n",
    "\n",
    "    pasc_subphenotype = pasc_subphenotype.query(\"~subphenotype_name.isnull()\")\n",
    "    pasc_subphenotype.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return pasc_subphenotype\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "This first step is to clean up the PASC definition reference spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASC_definition = pd.read_excel(\n",
    "    f'{external_source_path}/PASC_subphenotype.xlsx')\n",
    "\n",
    "# please reference the correct column names in your spreadsheet if using a different one\n",
    "PASC_definition.rename(columns={\n",
    "    'ICD-10-CM Code_clean': 'i10_code',\n",
    "    'pasc': 'ccsr_category',\n",
    "    'PASC Name Simple': 'pasc_name_simple'\n",
    "}, inplace=True\n",
    ")\n",
    "\n",
    "# a flag to filter any diagnosis that does not meet the stringent definition\n",
    "# you may comment this line out if the spreadsheet you are using already contains the diagnoses of interest\n",
    "PASC_definition = PASC_definition[PASC_definition['selected stringent'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_crosswalk = {\n",
    "  \"Abdominal pain and other digestive/abdomen signs and symptoms\": \"Digestive\" \n",
    ", \"Acute phlebitis; thrombophlebitis and thromboembolism\": \"Circulatory\" \n",
    ", \"Acute pulmonary embolism\": \"Circulatory\" \n",
    ", \"Anemia\": \"Blood\" \n",
    ", \"Circulatory signs and symptoms\": \"Circulatory\" \n",
    ", \"Diabetes mellitus with complication\": \"Endocrine\" \n",
    ", \"Fever\": \"General\" \n",
    ", \"Fluid and electrolyte disorders\": \"Endocrine\" \n",
    ", \"Headache; including migraine\": \"neurological\" \n",
    ", \"Malaise and fatigue\": \"neurological\" \n",
    ", \"Malnutrition\": \"Endocrine\" \n",
    ", \"Musculoskeletal pain, not low back pain\": \"Musculoskeletal\" \n",
    ", \"Nervous system signs and symptoms\": \"neurological\" \n",
    ", \"Neurocognitive disorders\": \"neurological\" \n",
    ", \"Nonspecific chest pain\": \"Circulatory\" \n",
    ", \"Other general signs and symptoms\": \"Endocrine\" \n",
    ", \"Other nervous system disorders (neither hereditary nor degenerative)\": \"neurological\" \n",
    ", \"Other specified and unspecified gastrointestinal disorders\": \"Digestive\" \n",
    ", \"Other specified and unspecified lower respiratory disease\": \"Respiratory\" \n",
    ", \"Other specified and unspecified skin disorders\": \"Skin\" \n",
    ", \"Other specified upper respiratory infections\": \"Respiratory\" \n",
    ", \"PASC-General\": \"PASC Diagnosis\" \n",
    ", \"Pressure ulcer of skin\": \"Skin\" \n",
    ", \"Respiratory signs and symptoms\": \"Respiratory\" \n",
    ", \"Sleep wake disorders\": \"neurological\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_crosswalk = {\n",
    "  \"Abdominal pain and other digestive/abdomen signs and symptoms\": \"brown\" \n",
    ", \"Acute phlebitis; thrombophlebitis and thromboembolism\": \"crimson\" \n",
    ", \"Acute pulmonary embolism\": \"crimson\" \n",
    ", \"Anemia\": \"orange\" \n",
    ", \"Circulatory signs and symptoms\": \"crimson\" \n",
    ", \"Diabetes mellitus with complication\": \"lightgreen\" \n",
    ", \"Fever\": \"lightgrey\" \n",
    ", \"Fluid and electrolyte disorders\": \"lightgreen\" \n",
    ", \"Headache; including migraine\": \"skyblue\" \n",
    ", \"Malaise and fatigue\": \"skyblue\" \n",
    ", \"Malnutrition\": \"lightgreen\" \n",
    ", \"Musculoskeletal pain, not low back pain\": \"pink\" \n",
    ", \"Nervous system signs and symptoms\": \"skyblue\" \n",
    ", \"Neurocognitive disorders\": \"skyblue\" \n",
    ", \"Nonspecific chest pain\": \"crimson\" \n",
    ", \"Other general signs and symptoms\": \"lightgreen\" \n",
    ", \"Other nervous system disorders (neither hereditary nor degenerative)\": \"skyblue\" \n",
    ", \"Other specified and unspecified gastrointestinal disorders\": \"brown\" \n",
    ", \"Other specified and unspecified lower respiratory disease\": \"tan\" \n",
    ", \"Other specified and unspecified skin disorders\": \"thistle\" \n",
    ", \"Other specified upper respiratory infections\": \"tan\" \n",
    ", \"PASC-General\": \"black\" \n",
    ", \"Pressure ulcer of skin\": \"thistle\" \n",
    ", \"Respiratory signs and symptoms\": \"tan\" \n",
    ", \"Sleep wake disorders\": \"skyblue\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign an organ system and a color (for visualizations) based on the crosswalks created earlier\n",
    "PASC_definition['system'] = PASC_definition['ccsr_category'].map(system_crosswalk)\n",
    "PASC_definition['color'] = PASC_definition['ccsr_category'].map(color_crosswalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by inner joining the table with ALL diagnoses with PASC definition reference spreadsheet\n",
    "# we are creating a smaller subset of the diagnosis table containing only the PASC like diagnoses\n",
    "# this step may not be necessary, but will help to optimize the query and its later functions\n",
    "pasc_diagnoses = pd.merge(\n",
    "    diagnosis,\n",
    "    PASC_definition[['i10_code']],\n",
    "    left_on='dx',\n",
    "    right_on='i10_code', \n",
    "    how='inner'\n",
    ")\n",
    "# dropping duplicated column\n",
    "pasc_diagnoses.drop(columns=('i10_code'), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasc_diff, pasc_date = get_pasc_category(\n",
    "    diagnosis=pasc_diagnoses,\n",
    "    index=index,\n",
    "    PASC_definition_reference=PASC_definition,\n",
    "    category='ccsr_category',\n",
    "    patid_column='syn_pt_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasc_subphenotype = get_pasc_subphenotype(\n",
    "    pasc_diff=pasc_diff,\n",
    "    patid_column='syn_pt_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasc_yn = pasc_diff.copy()\n",
    "\n",
    "# get a list of all columns (diagnosis categories) avoiding patid column in the first position\n",
    "col_list_ccsr = pasc_yn.columns[1:]\n",
    "\n",
    "# if +1 means it's pasc dx\n",
    "# if -1 means it's existing dx\n",
    "# if 0 means never been diagnosed\n",
    "pasc_yn[col_list_ccsr] = pasc_yn[col_list_ccsr].apply(lambda x: [1 if y > 30 else (-1 if y < -7 else 0) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pasc_pts(index:pd.DataFrame, pasc_yn:pd.DataFrame, pasc_subphenotype:pd.DataFrame, patid_column='syn_pt_id'):\n",
    "    '''get_pasc_pts function takes in a series of custom tables resulting from other pre-defined function to generate a list of patients\n",
    "    with their PASC status, subphenotype, and the index date. Please note this function only works for when the patient has one subphenotype.\n",
    "\n",
    "    Args:\n",
    "        index (pd.DataFrame): dataframe generated by get_index_event function.\n",
    "        pasc_yn (pd.DataFrame): dataframe with information whether a diagnosis category is PASC or pre-existing.\n",
    "        pasc_subphenotype (pd.DataFrame): dataframe generated by get_pasc_subphenotype function.\n",
    "        patid_column (str, optional): the column in the dataframe indicating the patient identifier. Defaults to 'syn_pt_id'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a dataframe with PASC and subphenotype information for all patients with an index date.\n",
    "    '''\n",
    "\n",
    "    # list of all patients with an index date\n",
    "    pasc_pts = index[[patid_column, 'index_date']].copy()\n",
    "\n",
    "    # dichotomous variable indicating PASC status\n",
    "    pasc_yn.set_index(patid_column, inplace=True)\n",
    "    pasc_pts['pasc_yn'] = np.where(pasc_pts[patid_column].isin(list(pasc_yn[(pasc_yn == 1).any(axis=1)].index)), 1, 0)\n",
    "    pasc_yn.reset_index(inplace=True)\n",
    "\n",
    "    pasc_pts = pd.merge(\n",
    "        pasc_pts,\n",
    "        pasc_subphenotype,\n",
    "        on='syn_pt_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return pasc_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasc_pts = get_pasc_pts(\n",
    "    index=index,\n",
    "    pasc_yn=pasc_yn,\n",
    "    pasc_subphenotype=pasc_subphenotype,\n",
    "    patid_column='syn_pt_id'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic clean up\n",
    "We now can clean up some of the demographic data elements to prepare for final data anlaysis.\n",
    "### Pre-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_age(df: pd.DataFrame, age_column: str):\n",
    "    '''categorize_age function takes a table containing a column with age of the patient and categorize the patient's age.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe with an age column.\n",
    "        age_column (str): Name of the column that contains the age of the patient. The column values should be int or float. This is often age of patient as of index event.\n",
    "\n",
    "    Returns:\n",
    "        pd.series: returns a series that can be directly assigned as a new column to any dataframe.\n",
    "    '''\n",
    "\n",
    "    age_group = np.select(\n",
    "        [\n",
    "            round(df[age_column]).between(0, 1, inclusive='left'),\n",
    "            round(df[age_column]).between(1, 4, inclusive='both'),\n",
    "            round(df[age_column]).between(5, 9, inclusive='both'),\n",
    "            round(df[age_column]).between(10, 15, inclusive='both'),\n",
    "            round(df[age_column]).between(16, 20, inclusive='both'),\n",
    "            round(df[age_column]).between(21, 35, inclusive='both'),\n",
    "            round(df[age_column]).between(36, 45, inclusive='both'),\n",
    "            round(df[age_column]).between(46, 55, inclusive='both'),\n",
    "            round(df[age_column]).between(56, 65, inclusive='both'),\n",
    "            round(df[age_column]) > 65\n",
    "        ],\n",
    "        [\n",
    "            '<1',\n",
    "            '1-4',\n",
    "            '5-9',\n",
    "            '10-15',\n",
    "            '16-20',\n",
    "            '21-35',\n",
    "            '36-45',\n",
    "            '46-55',\n",
    "            '56-65',\n",
    "            '66+'\n",
    "        ],\n",
    "        default='unknown'\n",
    "    )\n",
    "\n",
    "    return age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sex(df: pd.DataFrame, sex_column='sex'):\n",
    "    '''clean_sex function replaces PCORnet CDM value sets of sex with a human-readble value taken from the official PCORnet CDM dictionary. \n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe with ethnicity column with standard reference terminology values of PCORnet CDM. This is often the standard DEMOGRAPHIC table.\n",
    "        sex_column (str, optional): Name of the column containing the sex information. Defaults to 'sex'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the same input dataframe (i.e. df) with the values of sex_column replaced accordingly.\n",
    "    '''\n",
    "    df.replace({\n",
    "        sex_column: {\n",
    "            'A': 'Other/Missing/Unknown',\n",
    "            'F': 'Female',\n",
    "            'M': 'Male',\n",
    "            'NI': 'Other/Missing/Unknown',\n",
    "            'UN': 'Other/Missing/Unknown',\n",
    "            'OT': 'Other/Missing/Unknown'\n",
    "        }}, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_race(df: pd.DataFrame, race_column='race'):\n",
    "    '''clean_race function replaces PCORnet CDM value sets of race with a human-readble value taken from the official PCORnet CDM dictionary.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe with RACE column with standard reference terminology values of PCORnet CDM. This is often the standard DEMOGRAPHIC table.\n",
    "        race_column (str, optional): Name of the column containing the race information. Defaults to 'race'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the same input dataframe (i.e. df) with the values of race_column replaced accordingly.\n",
    "    '''\n",
    "\n",
    "    df.replace({\n",
    "        race_column: {\n",
    "            '01': 'American Indian or Alaska Native',\n",
    "            '1': 'American Indian or Alaska Native', # not a standard reference terminology\n",
    "            '02': 'Asian',\n",
    "            '2': 'Asian',  # not a standard reference terminology\n",
    "            '03': 'Black or African American',\n",
    "            '3': 'Black or African American',  # not a standard reference terminology\n",
    "            '04': 'Native Hawaiian or Other Pacific Islander',\n",
    "            '4': 'Native Hawaiian or Other Pacific Islander', # not a standard reference terminology\n",
    "            '05': 'White',\n",
    "            '5': 'White',  # not a standard reference terminology\n",
    "            '06': 'Multiple race',\n",
    "            '6': 'Multiple race',  # not a standard reference terminology\n",
    "            '07': 'Refuse to answer',\n",
    "            '7': 'Refuse to answer',  # not a standard reference terminology\n",
    "            'NI': 'No race information',\n",
    "            '0': 'Unknown',  # not a standard reference terminology\n",
    "            'UN': 'Unknown',\n",
    "            'OT': 'Other'\n",
    "        }}, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ethnicity(df: pd.DataFrame, ethnicity_column='hispanic'):\n",
    "    '''clean_ethnicity function replaces PCORnet CDM value sets of ethnicity with a human-readble value taken from the official PCORnet CDM dictionary.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe with ethnicity column with standard reference terminology values of PCORnet CDM. This is often the standard DEMOGRAPHIC table.\n",
    "        ethnicity_column (str, optional): Name of the column containing the ethnicity information. Defaults to 'hispanic'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the same input dataframe (i.e. df) with the values of ethnicity_column replaced accordingly.\n",
    "    '''\n",
    "\n",
    "    df.replace({\n",
    "        ethnicity_column: {\n",
    "            'Y': 'Hispanic',\n",
    "            'N': 'Not hispanic',\n",
    "            'R': 'Refuse to answer',\n",
    "            'NI': 'No ethnicity information',\n",
    "            'UN': 'Unknown',\n",
    "            'OT': 'Other'\n",
    "        }}, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_race_ethnicity(df: pd.DataFrame, ethnicity_column='hispanic', race_column='race'):\n",
    "    '''categorize_race_ethnicity function uses the already processed race and ethnicity values to combine and categorize the patients per qtwg's categories.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe with ethnicity column with standard reference terminology values of PCORnet CDM. This is often the standard DEMOGRAPHIC table.\n",
    "        ethnicity_column (str, optional): Name of the column containing the ethnicity information. Defaults to 'hispanic'.\n",
    "        race_column (str, optional): Name of the column containing the race information. Defaults to 'race'.\n",
    "\n",
    "    Returns:\n",
    "        pd.series: returns a series that can be directly assigned as a new column to any dataframe.\n",
    "    '''\n",
    "\n",
    "    race_ethnicity = np.select(\n",
    "        [\n",
    "            ((df[ethnicity_column].isin(['Not hispanic'])) & (df[race_column].isin(['White']))),\n",
    "            ((df[ethnicity_column].isin(['Not hispanic'])) & (df[race_column].isin(['Black or African American']))),\n",
    "            (df[ethnicity_column].isin(['Hispanic'])),\n",
    "            ((df[ethnicity_column].isin(['Not hispanic'])) & (df[race_column].isin(['Asian']))),\n",
    "            (\n",
    "                (df[race_column].isin(['Native Hawaiian or Other Pacific Islander']))\n",
    "                | (df[race_column].isin(['American Indian or Alaska Native']))\n",
    "                | (df[ethnicity_column].isin(['Other']))\n",
    "                | (df[race_column].isin(['Other', 'Multiple race']))\n",
    "            ), \n",
    "            (\n",
    "                (df[ethnicity_column].isin(\n",
    "                    ['Unknown', 'Refuse to answer', 'No ethnicity information', '']))\n",
    "                | (df[race_column].isin(['Unknown', 'Refuse to answer', 'No race information', '']))\n",
    "            )\n",
    "        ], [\n",
    "            'Non-Hispanic white',\n",
    "            'Non-Hispanic black',\n",
    "            'Hispanic',\n",
    "            'Non-hispanic Asian',\n",
    "            'Other',\n",
    "            'Missing/Unknown'\n",
    "        ], default='ISSUE WITH RACE OR ETHNICITY COLUMN'\n",
    "    )\n",
    "\n",
    "    return race_ethnicity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate age as of today then categorize the age\n",
    "# please note, for CSC queries you may often need to calcualte age at the time of index event unless stated otherwise\n",
    "demographic['age_as_of_today'] = (datetime.date.today() - demographic['birth_date']) / np.timedelta64(1, 'Y')\n",
    "demographic['age_as_of_today_group'] = categorize_age(df=demographic, age_column='age_as_of_today')\n",
    "\n",
    "# clean SEX column\n",
    "demographic = clean_sex(df=demographic, sex_column='sex')\n",
    "\n",
    "# clean RACE and HISPANIC column then categorize patients based on race and ethnicity combined \n",
    "demographic = clean_race(df=demographic, race_column='race')\n",
    "demographic = clean_ethnicity(df=demographic, ethnicity_column='hispanic')\n",
    "demographic['race_ethnicity'] = categorize_race_ethnicity(df=demographic, race_column='race', ethnicity_column='hispanic')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "We now have all data clean and processed ready to be analyzed. The analysis portion of the notebook is optional and may varry per query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patid_column = 'syn_pt_id'\n",
    "sex_column = 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the flat file with the index table to ensure every patient will have an index date\n",
    "flat = index[['site', patid_column, 'index_date']].copy()\n",
    "\n",
    "# inner joining to demographic table to collect demographic information\n",
    "flat = flat.merge(\n",
    "    demographic[[patid_column, sex_column, 'race_ethnicity', 'birth_date', 'age_as_of_today', 'age_as_of_today_group']],\n",
    "    on=patid_column,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# calculate and categorize age at the time of index event\n",
    "flat['age_as_of_index'] = (flat['index_date'] - flat['birth_date']) / np.timedelta64(1, 'Y')\n",
    "flat['age_as_of_index_group'] = categorize_age(df=flat, age_column='age_as_of_index')\n",
    "\n",
    "# inner joining to pasc_pts table that contains PASC information for all patients regardless of their status\n",
    "flat = flat.merge(\n",
    "    pasc_pts,\n",
    "    on=[patid_column, 'index_date'],\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat.pivot_table(\n",
    "    values=patid_column,\n",
    "    aggfunc='nunique',\n",
    "    index=sex_column,\n",
    "    columns='pasc_yn',\n",
    "    margins=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
